{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28aa60b6",
   "metadata": {},
   "source": [
    "# 02 ‚Äî Data Preprocessing\n",
    "\n",
    "This notebook cleans and prepares the raw dataset for model training.\n",
    "\n",
    "**Data Notes:**\n",
    "1.  **User Mentions**: `@user` mentions were cleaned prior to corpus creation.\n",
    "2.  **Special Tags**: Tags like `[GROSERIA]` or `[PERSONA]` were added during an obfuscation task before corpus creation. We strictly preserve their casing.\n",
    "\n",
    "**Preprocessing Logic:**\n",
    "1.  **Context Construction**: We concatenate `QuoteText` + `TweetText` to respect the stimulus-response order of the conversation.\n",
    "2.  **Cleaning**:\n",
    "    -   Remove URLs (cleaning artifacts).\n",
    "    -   Demojize emojis.\n",
    "    -   Lowercase standard text, but **preserve uppercase Tags**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e74d14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T16:03:55.819546Z",
     "iopub.status.busy": "2026-02-14T16:03:55.819196Z",
     "iopub.status.idle": "2026-02-14T16:04:03.786854Z",
     "shell.execute_reply": "2026-02-14T16:04:03.780875Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Ensure data directories exist\n",
    "os.makedirs('../data/processed', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2372f26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T16:04:03.803769Z",
     "iopub.status.busy": "2026-02-14T16:04:03.802563Z",
     "iopub.status.idle": "2026-02-14T16:04:03.927921Z",
     "shell.execute_reply": "2026-02-14T16:04:03.923245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.12.12\n",
      "IPython version      : 9.10.0\n",
      "\n",
      "numpy  : 1.26.4\n",
      "pandas : 3.0.0\n",
      "sklearn: 1.8.0\n",
      "emoji  : 2.15.0\n",
      "\n",
      "Compiler    : Clang 17.0.0 (clang-1700.6.3.2)\n",
      "OS          : Darwin\n",
      "Release     : 25.2.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -n -m -p numpy,pandas,sklearn,emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c33dc22",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "We construct the text field by placing `QuoteText` before `TweetText`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70788923",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T16:04:03.940113Z",
     "iopub.status.busy": "2026-02-14T16:04:03.939042Z",
     "iopub.status.idle": "2026-02-14T16:04:04.314168Z",
     "shell.execute_reply": "2026-02-14T16:04:04.278159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape: (3000, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Que ganas de fumarme un porrito y tomarme una...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Escuchar lana del rey es como tomarme una l√≠ne...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A las 10 am ya tom√© un latte, un expreso y est...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Todos miran la moneda menos Maradona, que mira...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amo tomarme una l√≠nea de colectivos que no con...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  \"Que ganas de fumarme un porrito y tomarme una...  NEGATIVE\n",
       "1  Escuchar lana del rey es como tomarme una l√≠ne...  NEGATIVE\n",
       "2  A las 10 am ya tom√© un latte, un expreso y est...  NEGATIVE\n",
       "3  Todos miran la moneda menos Maradona, que mira...  NEGATIVE\n",
       "4  Amo tomarme una l√≠nea de colectivos que no con...  NEGATIVE"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/corpus.csv')\n",
    "print(f\"Original Shape: {df.shape}\")\n",
    "\n",
    "# Create 'text' column: QuoteText (if exists) + TweetText\n",
    "# Adding a space only if QuoteText exists is handled naturally by fillna('') + ' ' if we are careful, \n",
    "# but simple concat with separator is safer.\n",
    "df['quote_safe'] = df['QuoteText'].fillna('')\n",
    "df['text'] = df.apply(lambda x: (x['quote_safe'] + \" \" + x['TweetText']).strip(), axis=1)\n",
    "\n",
    "df['label'] = df['Categorization']\n",
    "\n",
    "# Keep only processed columns\n",
    "df = df[['text', 'label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3906f9c",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Functions\n",
    "\n",
    "We define `clean_text` to:\n",
    "-   Remove URLs.\n",
    "-   Demojize.\n",
    "-   Lowercase text *except* special tags matching `[TAG]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "843774a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T16:04:04.345260Z",
     "iopub.status.busy": "2026-02-14T16:04:04.344601Z",
     "iopub.status.idle": "2026-02-14T16:04:04.421057Z",
     "shell.execute_reply": "2026-02-14T16:04:04.418021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Hola world! üíä Mira https://t.co/xyz [GROSERIA] y [ANATOMIA] #fiesta\n",
      "Cleaned:  hola world! :p√≠ldora: mira [GROSERIA] y [ANATOMIA] #fiesta\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # 1. Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # 2. Demojize emojis (e.g. üíä -> :pill:) with delimiters\n",
    "    text = emoji.demojize(text, language='es', delimiters=(\" :\", \": \"))\n",
    "    \n",
    "    # 3. Handle Casing: Lowercase everything EXCEPT tags like [TAG]\n",
    "    # Split by tags. Capturing group () keeps the delimiter (the tag).\n",
    "    parts = re.split(r'(\\[[A-Z√Å√â√ç√ì√ö√ë]+\\])', text)\n",
    "    processed_parts = []\n",
    "    for part in parts:\n",
    "        if re.match(r'^\\[[A-Z√Å√â√ç√ì√ö√ë]+\\]$', part):\n",
    "            processed_parts.append(part) # Keep original case for Tags\n",
    "        else:\n",
    "            processed_parts.append(part.lower()) # Lowercase everything else\n",
    "            \n",
    "    text = \"\".join(processed_parts)\n",
    "    \n",
    "    # 4. Normalize whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Test the function\n",
    "sample = \"Hola world! üíä Mira https://t.co/xyz [GROSERIA] y [ANATOMIA] #fiesta\"\n",
    "print(f\"Original: {sample}\")\n",
    "print(f\"Cleaned:  {clean_text(sample)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f31b92",
   "metadata": {},
   "source": [
    "## 3. Apply Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbe774a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T16:04:04.429057Z",
     "iopub.status.busy": "2026-02-14T16:04:04.428108Z",
     "iopub.status.idle": "2026-02-14T16:04:05.570224Z",
     "shell.execute_reply": "2026-02-14T16:04:05.566406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of cleaned text:\n",
      "- desde ayer estoy sin luz. es me√°s f√°cil dejar de tomar merca que de usar energ√≠a el√©ctrica. sufro abstinencia de tv, pc, play y heladera.\n",
      "- habr√≠a que tomar una linea mas aristotelica para venderle a la gente lo trascendente, y la idea de lo eterno como fuente de verdad objetiva y marco moral. pero yo no descartar√≠a a maquiavelo por la din√°mica de poder que es necesario entender para poder interactuar\n",
      "- y ojala que si llegas a tomar merca este finde, te [GROSERIA] y sea ibuprofeno pisado.\n",
      "- fumaban un porro en un patio ajeno y fueron detenidos\n",
      "- y cuando escucho lust for life de iggy pop me dan ganas de inyectarme hero√≠na en el metro\n"
     ]
    }
   ],
   "source": [
    "df['text_clean'] = df['text'].apply(clean_text)\n",
    "print(\"Sample of cleaned text:\")\n",
    "for txt in df['text_clean'].sample(5, random_state=42):\n",
    "    print(f\"- {txt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5f0016",
   "metadata": {},
   "source": [
    "## 4. Train / Validation / Test Split\n",
    "\n",
    "Stratified split:\n",
    "-   **Train**: 70%\n",
    "-   **Validation**: 15%\n",
    "-   **Test**: 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f8ad56b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T16:04:05.583663Z",
     "iopub.status.busy": "2026-02-14T16:04:05.582437Z",
     "iopub.status.idle": "2026-02-14T16:04:05.641974Z",
     "shell.execute_reply": "2026-02-14T16:04:05.636066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (2100, 3)\n",
      "Val size:   (450, 3)\n",
      "Test size:  (450, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['label'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
    "\n",
    "print(f\"Train size: {train_df.shape}\")\n",
    "print(f\"Val size:   {val_df.shape}\")\n",
    "print(f\"Test size:  {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ec713",
   "metadata": {},
   "source": [
    "## 5. Save Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "593f1afc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-14T16:04:05.653725Z",
     "iopub.status.busy": "2026-02-14T16:04:05.652603Z",
     "iopub.status.idle": "2026-02-14T16:04:05.752233Z",
     "shell.execute_reply": "2026-02-14T16:04:05.746801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets saved to ../data/processed/\n"
     ]
    }
   ],
   "source": [
    "train_df.to_csv('../data/processed/train.csv', index=False)\n",
    "val_df.to_csv('../data/processed/val.csv', index=False)\n",
    "test_df.to_csv('../data/processed/test.csv', index=False)\n",
    "\n",
    "print(\"Datasets saved to ../data/processed/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac76481",
   "metadata": {},
   "source": [
    "## Summary of the results\n",
    "\n",
    "Preprocessing complete with refined logic:\n",
    "*   **Context**: `QuoteText` precedes `TweetText`.\n",
    "*   **Cleaning**: URLs removed, emojis demojized, text lowercased.\n",
    "*   **Tag Preservation**: `[TAG]` tokens retain their uppercase formatting.\n",
    "*   **Output**: 2100 Train / 450 Val / 450 Test samples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (drugs-usage)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
