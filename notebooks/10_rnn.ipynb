{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baffeef6",
   "metadata": {},
   "source": [
    "# 10 — RNN (Bidirectional LSTM)\n",
    "\n",
    "A **Recurrent Neural Network** using a Bidirectional LSTM for text classification.\n",
    "\n",
    "Unlike CNN (which captures local n-gram patterns), LSTM processes the entire sequence\n",
    "step-by-step, capturing **long-range dependencies** and contextual meaning.\n",
    "\n",
    "Bidirectional processing reads the text both forward and backward for richer representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaa16fe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:45:55.698481Z",
     "iopub.status.busy": "2026-02-16T21:45:55.697463Z",
     "iopub.status.idle": "2026-02-16T21:46:02.143175Z",
     "shell.execute_reply": "2026-02-16T21:46:02.142233Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.4.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3123, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3178, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3641, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3701, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/d7/53rh3m0d4j983v3p54wjrlf80000gn/T/ipykernel_52741/1782491361.py\", line 3, in <module>\n",
      "    import torch\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/lhbelfanti/.pyenv/versions/3.12.12/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import os\n",
    "# Corpus Configuration\n",
    "CORPUS_NAME = 'raw_corpus' # Options: 'pre-filtered-corpus', 'raw_corpus'\n",
    "PROCESSED_DATA_DIR = f'../data/processed/{CORPUS_NAME}'\n",
    "MODELS_DIR_BASE = f'../models/{CORPUS_NAME}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "652c88c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:46:02.148382Z",
     "iopub.status.busy": "2026-02-16T21:46:02.147465Z",
     "iopub.status.idle": "2026-02-16T21:46:02.222154Z",
     "shell.execute_reply": "2026-02-16T21:46:02.220748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.12.12\n",
      "IPython version      : 9.10.0\n",
      "\n",
      "numpy  : 2.4.2\n",
      "pandas : 3.0.0\n",
      "torch  : 2.2.2\n",
      "gensim : 4.4.0\n",
      "sklearn: 1.8.0\n",
      "\n",
      "Compiler    : Clang 17.0.0 (clang-1700.6.3.2)\n",
      "OS          : Darwin\n",
      "Release     : 25.2.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -v -n -m -p numpy,pandas,torch,gensim,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73012b8",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b8f4b21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:46:02.228767Z",
     "iopub.status.busy": "2026-02-16T21:46:02.228096Z",
     "iopub.status.idle": "2026-02-16T21:46:02.239072Z",
     "shell.execute_reply": "2026-02-16T21:46:02.237715Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 50\n",
    "EMBED_DIM = 100\n",
    "LABEL_MAP = {'NEGATIVE': 0, 'POSITIVE': 1}\n",
    "\n",
    "def build_embedding_matrix(w2v_model):\n",
    "    vocab = w2v_model.wv.key_to_index\n",
    "    matrix = np.zeros((len(vocab) + 1, EMBED_DIM))\n",
    "    word2idx = {'<PAD>': 0}\n",
    "    for word, idx in vocab.items():\n",
    "        word2idx[word] = idx + 1\n",
    "        matrix[idx + 1] = w2v_model.wv[word]\n",
    "    return matrix, word2idx\n",
    "\n",
    "def texts_to_sequences(texts, word2idx, max_len):\n",
    "    sequences = []\n",
    "    for text in texts:\n",
    "        tokens = str(text).split()\n",
    "        seq = [word2idx.get(w, 0) for w in tokens[:max_len]]\n",
    "        seq += [0] * (max_len - len(seq))\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c8cb40",
   "metadata": {},
   "source": [
    "## 2. Model Definition\n",
    "\n",
    "Embedding → Bidirectional LSTM (hidden=64) → Dropout → FC → Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4dd991d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:46:02.243782Z",
     "iopub.status.busy": "2026-02-16T21:46:02.243327Z",
     "iopub.status.idle": "2026-02-16T21:46:02.256802Z",
     "shell.execute_reply": "2026-02-16T21:46:02.255193Z"
    }
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_dim=64, dropout=0.3):\n",
    "        super().__init__()\n",
    "        vocab_size, embed_dim = embedding_matrix.shape\n",
    "        \n",
    "        # Pre-trained embedding (frozen)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.embedding.weight = nn.Parameter(torch.FloatTensor(embedding_matrix))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            embed_dim, hidden_dim,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            num_layers=1\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Bidirectional → hidden_dim * 2\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len)\n",
    "        x = self.embedding(x)  # (batch, seq_len, embed_dim)\n",
    "        \n",
    "        # LSTM output: (batch, seq_len, hidden*2)\n",
    "        lstm_out, (hidden, _) = self.lstm(x)\n",
    "        \n",
    "        # Concatenate final hidden states from both directions\n",
    "        # hidden: (num_layers*2, batch, hidden_dim)\n",
    "        hidden_fwd = hidden[-2]  # Last layer, forward\n",
    "        hidden_bwd = hidden[-1]  # Last layer, backward\n",
    "        combined = torch.cat((hidden_fwd, hidden_bwd), dim=1)  # (batch, hidden*2)\n",
    "        \n",
    "        out = self.dropout(combined)\n",
    "        out = torch.sigmoid(self.fc(out)).squeeze(1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a37935c",
   "metadata": {},
   "source": [
    "## 3. Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "616d0eab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:46:02.264168Z",
     "iopub.status.busy": "2026-02-16T21:46:02.263647Z",
     "iopub.status.idle": "2026-02-16T21:46:02.279772Z",
     "shell.execute_reply": "2026-02-16T21:46:02.278482Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_rnn(variation_name, data_dir, w2v_path, output_dir, epochs=20, lr=1e-3, batch_size=32):\n",
    "    print(f\"\\n{'='*20} BiLSTM: {variation_name} {'='*20}\")\n",
    "    \n",
    "    # Load Word2Vec\n",
    "    w2v = Word2Vec.load(w2v_path)\n",
    "    embed_matrix, word2idx = build_embedding_matrix(w2v)\n",
    "    print(f\"Embedding matrix: {embed_matrix.shape}\")\n",
    "    \n",
    "    # Load data\n",
    "    train_df = pd.read_csv(f'{data_dir}/train.csv').fillna('')\n",
    "    test_df  = pd.read_csv(f'{data_dir}/test.csv').fillna('')\n",
    "    \n",
    "    X_train = texts_to_sequences(train_df['text_clean'], word2idx, MAX_LEN)\n",
    "    X_test  = texts_to_sequences(test_df['text_clean'], word2idx, MAX_LEN)\n",
    "    y_train = train_df['label'].map(LABEL_MAP).values.astype(np.float32)\n",
    "    y_test  = test_df['label'].map(LABEL_MAP).values.astype(np.float32)\n",
    "    \n",
    "    # DataLoaders\n",
    "    train_ds = TensorDataset(torch.LongTensor(X_train), torch.FloatTensor(y_train))\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Model\n",
    "    model = BiLSTM(embed_matrix)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()), lr=lr\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_x)\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"  Epoch {epoch+1}/{epochs} — Loss: {total_loss/len(train_loader):.4f}\")\n",
    "    \n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(torch.LongTensor(X_test))\n",
    "    y_pred = np.array((preds >= 0.5).int().tolist())\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nBiLSTM ({variation_name}) Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test.astype(int), y_pred))\n",
    "    \n",
    "    # Save\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    torch.save(model.state_dict(), f'{output_dir}/model.pt')\n",
    "    print(f\"Model saved to {output_dir}/model.pt\")\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6ed1ed",
   "metadata": {},
   "source": [
    "## 4. Run All Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d44db4c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:46:02.284405Z",
     "iopub.status.busy": "2026-02-16T21:46:02.283907Z",
     "iopub.status.idle": "2026-02-16T21:48:17.771884Z",
     "shell.execute_reply": "2026-02-16T21:48:17.770176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== BiLSTM: Standard ====================\n",
      "Embedding matrix: (2332, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5/20 — Loss: 0.4744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/20 — Loss: 0.4087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 15/20 — Loss: 0.3422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 20/20 — Loss: 0.2794\n",
      "\n",
      "BiLSTM (Standard) Accuracy: 0.7871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79       232\n",
      "           1       0.81      0.75      0.78       233\n",
      "\n",
      "    accuracy                           0.79       465\n",
      "   macro avg       0.79      0.79      0.79       465\n",
      "weighted avg       0.79      0.79      0.79       465\n",
      "\n",
      "Model saved to ../models/raw_corpus/rnn/standard/model.pt\n",
      "\n",
      "==================== BiLSTM: Irony ====================\n",
      "Embedding matrix: (2323, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5/20 — Loss: 0.4862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/20 — Loss: 0.4072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 15/20 — Loss: 0.3543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 20/20 — Loss: 0.2936\n",
      "\n",
      "BiLSTM (Irony) Accuracy: 0.7978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80       232\n",
      "           1       0.81      0.78      0.79       233\n",
      "\n",
      "    accuracy                           0.80       465\n",
      "   macro avg       0.80      0.80      0.80       465\n",
      "weighted avg       0.80      0.80      0.80       465\n",
      "\n",
      "Model saved to ../models/raw_corpus/rnn/irony/model.pt\n",
      "\n",
      "==================== BiLSTM: Obfuscated ====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix: (2303, 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5/20 — Loss: 0.4971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/20 — Loss: 0.3986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 15/20 — Loss: 0.3472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 20/20 — Loss: 0.2896\n",
      "\n",
      "BiLSTM (Obfuscated) Accuracy: 0.7871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79       232\n",
      "           1       0.81      0.76      0.78       233\n",
      "\n",
      "    accuracy                           0.79       465\n",
      "   macro avg       0.79      0.79      0.79       465\n",
      "weighted avg       0.79      0.79      0.79       465\n",
      "\n",
      "Model saved to ../models/raw_corpus/rnn/obfuscated/model.pt\n"
     ]
    }
   ],
   "source": [
    "acc_standard = train_rnn(\"Standard\", f\"{PROCESSED_DATA_DIR}/standard\", f\"{MODELS_DIR_BASE}/word2vec/standard/word2vec.model\", f\"{MODELS_DIR_BASE}/rnn/standard\")\n",
    "\n",
    "acc_irony = train_rnn(\"Irony\", f\"{PROCESSED_DATA_DIR}/irony\", f\"{MODELS_DIR_BASE}/word2vec/irony/word2vec.model\", f\"{MODELS_DIR_BASE}/rnn/irony\")\n",
    "\n",
    "acc_obfuscated = train_rnn(\"Obfuscated\", f\"{PROCESSED_DATA_DIR}/obfuscated\", f\"{MODELS_DIR_BASE}/word2vec/obfuscated/word2vec.model\", f\"{MODELS_DIR_BASE}/rnn/obfuscated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1ec7bc",
   "metadata": {},
   "source": [
    "## 5. Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "507be8b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-16T21:48:17.779650Z",
     "iopub.status.busy": "2026-02-16T21:48:17.779003Z",
     "iopub.status.idle": "2026-02-16T21:48:17.790693Z",
     "shell.execute_reply": "2026-02-16T21:48:17.788698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Comparison ===\n",
      "Standard: 0.7871\n",
      "Irony:    0.7978\n",
      "Obfuscated: 0.7871\n",
      "Impact of Irony features: +0.0108\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Final Comparison ===\")\n",
    "print(f\"Standard: {acc_standard:.4f}\")\n",
    "print(f\"Irony:    {acc_irony:.4f}\")\n",
    "print(f\"Obfuscated: {acc_obfuscated:.4f}\")\n",
    "diff = acc_irony - acc_standard\n",
    "print(f\"Impact of Irony features: {diff:+.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
